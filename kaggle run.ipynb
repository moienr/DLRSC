{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/moienr/DLRSC.git","metadata":{"execution":{"iopub.status.busy":"2023-07-08T18:44:41.814097Z","iopub.execute_input":"2023-07-08T18:44:41.814686Z","iopub.status.idle":"2023-07-08T18:44:44.881555Z","shell.execute_reply.started":"2023-07-08T18:44:41.814638Z","shell.execute_reply":"2023-07-08T18:44:44.880329Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'DLRSC'...\nremote: Enumerating objects: 20, done.\u001b[K\nremote: Counting objects: 100% (20/20), done.\u001b[K\nremote: Compressing objects: 100% (15/15), done.\u001b[K\nremote: Total 20 (delta 8), reused 15 (delta 5), pack-reused 0\u001b[K\nReceiving objects: 100% (20/20), 12.33 MiB | 12.95 MiB/s, done.\nResolving deltas: 100% (8/8), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nIN_KAGGLE = 'KAGGLE_URL_BASE' in os.environ\nIN_KAGGLE","metadata":{"execution":{"iopub.status.busy":"2023-07-08T18:44:44.883497Z","iopub.execute_input":"2023-07-08T18:44:44.883977Z","iopub.status.idle":"2023-07-08T18:44:44.900929Z","shell.execute_reply.started":"2023-07-08T18:44:44.883945Z","shell.execute_reply":"2023-07-08T18:44:44.899997Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"if IN_KAGGLE:\n    import time\n    import os\n    sleep_time = 5\n    while not os.path.exists(\"/kaggle/working/DLRSC\"):\n        print(\"didn't find the path, wating {sleep_time} more seconds...\")\n        time.sleep(sleep_time)\n    print(\"path found...\")\n    import sys\n    sys.path.append(\"/kaggle/working/DLRSC\")","metadata":{"execution":{"iopub.status.busy":"2023-07-08T18:44:44.903576Z","iopub.execute_input":"2023-07-08T18:44:44.904792Z","iopub.status.idle":"2023-07-08T18:44:44.912084Z","shell.execute_reply.started":"2023-07-08T18:44:44.904754Z","shell.execute_reply":"2023-07-08T18:44:44.911112Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"path found...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# COIL","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport numpy as np\nimport scipy.io as sio\nimport matplotlib\nmatplotlib.use('agg')\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import save_image\nfrom scipy.sparse.linalg import svds\nfrom sklearn import cluster\nfrom sklearn.preprocessing import normalize\nfrom munkres import Munkres\nimport os, random\nimport yaml\n\n\n# ===========================================================================================\n# ======================================= NN Model ==========================================\n# ===========================================================================================\nclass ConvAEIn(nn.Module):\n    def __init__(self, params):\n        super(ConvAEIn, self).__init__()\n        kernelSize = params[\"kernelSize\"]\n        numHidden = params[\"numHidden\"]\n\n        self.batchSize = params[\"numSubj\"] * params[\"numPerSubj\"]\n\n        self.padEncL1 = nn.ZeroPad2d((0, 2, 0, 2))\n        self.encL1 = nn.Conv2d(1, numHidden[0], kernel_size=kernelSize[0], stride=2)\n\n        self.padDecL1 = nn.ZeroPad2d((0, -1, 0, -1))\n        self.decL1 = nn.ConvTranspose2d(numHidden[0], 1, kernel_size=kernelSize[0], stride=2)\n\n    def forward(self, X):\n        Z1 = F.relu(self.encL1(self.padEncL1(X)))\n\n        output = F.relu(self.padDecL1(self.decL1(Z1)))\n        return output\n# ===========================================================================================\n# ======================================= NN Model ==========================================\n# ===========================================================================================\n\nfrom torchvision import models\nprint(\"testing Resnet...\")\nclass ResNet18(nn.Module):\n    def __init__(self, in_channels=1, hidden=50):\n        super().__init__()\n        self.resnet = models.resnet18(weights=None)\n        self.resnet.conv1 = nn.Conv2d(in_channels, 10, kernel_size=3, stride=2, padding=1, bias=False)\n        self.relu = nn.LeakyReLU()\n\n        # Replace residual blocks in layers 2, 3, and 4 with identity blocks\n        self.resnet.layer1 = nn.Sequential(\n            nn.Conv2d(10, 20, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(20),\n            nn.LeakyReLU(),\n            nn.Conv2d(20, 50, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(50)\n        )\n\n    def forward(self, x):\n        x = self.resnet.conv1(x)\n        x = self.relu(x)\n        x = self.resnet.layer1(x) # Add the residual connection\n        return x\n\n\n\nclass ConvAE(nn.Module):\n    def __init__(self, params):\n        super(ConvAE, self).__init__()\n        kernelSize = params[\"kernelSize\"]\n        numHidden = params[\"numHidden\"]\n        cte = params[\"cte\"]\n        numSubj = params[\"numSubj\"]\n        rankEs = params[\"rankE\"]\n\n        self.batchSize = numSubj * params[\"numPerSubj\"]\n\n        # self.padEncL1 = nn.ZeroPad2d((0, 2, 0, 2))\n        # self.encL1 = nn.Conv2d(1, numHidden[0], kernel_size=kernelSize[0], stride=2)\n        self.resnet18 = ResNet18(in_channels=1)\n\n        cc = np.zeros((self.batchSize, rankEs))\n\n        self.C1 = nn.Parameter(Variable(torch.Tensor(cc), requires_grad=True))\n\n        self.padDecL1 = nn.ZeroPad2d((0, -1, 0, -1))\n        self.decL1 = nn.ConvTranspose2d(numHidden[0], 1, kernel_size=kernelSize[0], stride=2)\n\n    def forward(self, X):\n        Z1 = F.relu(self.resnet18(X))\n\n        Y = (torch.matmul(self.C1, torch.transpose(self.C1, 0, 1))-torch.diag(torch.diag(torch.matmul(self.C1, torch.transpose(self.C1, 0, 1))))).mm(Z1.view(self.batchSize, -1))\n        Y = Y.view(Z1.size())\n\n        output = F.relu(self.padDecL1(self.decL1(Y)))\n        return Z1, Y, self.C1, output\n    \n\n\n# ===========================================================================================\n# ========================== Subspace Clustering Method DLRSC ==============================\n# ===========================================================================================\ndef subspaceClusteringMLRDSC(images, params):\n    numSubjects = params[\"numSubj\"]\n    numPerSubj  = params[\"numPerSubj\"]\n    numEpochs   = params[\"numEpochs\"]\n    fileName    = params[\"preTrainedModel\"]\n    alpha = params[\"alpha\"]\n    lr    = params[\"lr\"]\n    T     = params[\"T\"]\n    cte   = params[\"cte\"]\n    seedValue = params[\"seedValue\"]\n    batchSize = numSubjects * numPerSubj\n    regparams = params[\"regparams\"]\n    label = params[\"label\"]\n    rankEs = params[\"rankE\"]\n    gamma_reg, lambda_reg = params[\"lambda\"], params[\"gamma\"]\n\n    coilSubjects = images\n    coilSubjects = coilSubjects.astype(float)\n    labelSubjects = label\n    labelSubjects = labelSubjects - labelSubjects.min() + 1\n    labelSubjects = np.squeeze(labelSubjects)\n\n    X = Variable(torch.Tensor(coilSubjects / 255.).cuda(), requires_grad=False)\n\n    preTrainedMod = torch.load(fileName)\n    CAE = ConvAE(params)\n    CAE = CAE.cuda()\n\n    parametersAE = dict([(name, param) for name, param in preTrainedMod.named_parameters()])\n\n    for name, param in CAE.named_parameters():\n        if name in parametersAE:\n            param_pre  = parametersAE[name]\n            param.data = param_pre.data\n\n    if params[\"seedFlag\"]:\n        random.seed(seedValue)\n        os.environ['PYTHONHASHSEED'] = str(seedValue)\n        np.random.seed(seedValue)\n        torch.manual_seed(seedValue)\n        torch.cuda.manual_seed(seedValue)\n        torch.cuda.manual_seed_all(seedValue)  # if you are using multi-GPU.\n        torch.backends.cudnn.benchmark = False\n        torch.backends.cudnn.deterministic = True\n\n    CAE.C1.data = (torch.Tensor(cte * np.random.randn(batchSize, rankEs))).cuda()\n\n    optimizer = torch.optim.Adam(CAE.parameters(), lr=lr)\n    numSamples = coilSubjects.shape[0]\n\n    for epoch in range(numEpochs + 1):\n        Z1, Y, C1, output = CAE(X)\n\n        regLoss   = gamma_reg * (torch.norm(C1, p=2)**2)\n        reconLoss =  (torch.norm(output - X, p=2) ** 2)\n        expLoss   = lambda_reg * (torch.norm(Z1 - Y, p=2) ** 2)\n        loss = reconLoss + regLoss + regparams * expLoss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if epoch > 0 and epoch % T == 0:\n            print(\"Losses  \" + \"Reconstruction: %.8f     Expression: %.8f     Regularization: %.8f\" % (reconLoss / numSamples, expLoss, regLoss))\n            mm1 = C1.detach().cpu().numpy()\n            Coef = thrC(np.dot(mm1, mm1.T), alpha)\n            yHat, _ = post_proC(Coef, labelSubjects.max(), params)\n            errorClus = err_rate(labelSubjects, yHat)\n            accuClus = 1 - errorClus\n            print(\"Accuracy after %d\" % (epoch), \"Iterations: %.4f\" % accuClus)\n\n    return (1 - accuClus)\n\ndef best_map(L1, L2):\n    # L1 should be the labels and L2 should be the clustering number we got\n    Label1 = np.unique(L1)\n    nClass1 = len(Label1)\n    Label2 = np.unique(L2)\n    nClass2 = len(Label2)\n    nClass = np.maximum(nClass1, nClass2)\n    G = np.zeros((nClass, nClass))\n    for i in range(nClass1):\n        ind_cla1 = L1 == Label1[i]\n        ind_cla1 = ind_cla1.astype(float)\n        for j in range(nClass2):\n            ind_cla2 = L2 == Label2[j]\n            ind_cla2 = ind_cla2.astype(float)\n            G[i, j] = np.sum(ind_cla2 * ind_cla1)\n    m = Munkres()\n    index = m.compute(-G.T)\n    index = np.array(index)\n    c = index[:, 1]\n    newL2 = np.zeros(L2.shape)\n    for i in range(nClass2):\n        newL2[L2 == Label2[i]] = Label1[c[i]]\n    return newL2\n\ndef thrC(C, ro):\n    if ro < 1:\n        N = C.shape[1]\n        Cp = np.zeros((N, N))\n        S = np.abs(np.sort(-np.abs(C), axis=0))\n        Ind = np.argsort(-np.abs(C), axis=0)\n        for i in range(N):\n            cL1 = np.sum(S[:, i]).astype(float)\n            stop = False\n            csum = 0\n            t = 0\n            while (stop == False):\n                csum = csum + S[t, i]\n                if csum > ro * cL1:\n                    stop = True\n                    Cp[Ind[0:t + 1, i], i] = C[Ind[0:t + 1, i], i]\n                t = t + 1\n    else:\n        Cp = C\n    return Cp\n\ndef post_proC(C, K, params):\n    # C: coefficient matrix, K: number of clusters, d: dimension of each subspace\n    d = params[\"post_proc\"][0]\n    alpha = params[\"post_proc\"][1]\n\n    C = 0.5 * (C + C.T)\n    C = C - np.diag(np.diag(C)) + np.eye(C.shape[0],C.shape[0])\n    r = d * K + 1\n    U, S, _ = svds(C, r, v0=np.ones(C.shape[0]))\n    U = U[:, ::-1]\n    S = np.sqrt(S[::-1])\n    S = np.diag(S)\n    U = U.dot(S)\n    U = normalize(U, norm='l2', axis=1)\n    Z = U.dot(U.T)\n    Z = Z * (Z > 0)\n    L = np.abs(Z ** alpha)\n    L = L / L.max()\n    L = 0.5 * (L + L.T)\n    spectral = cluster.SpectralClustering(n_clusters=K, eigen_solver='arpack', affinity='precomputed',\n                                          assign_labels='discretize')\n    spectral.fit(L)\n    grp = spectral.fit_predict(L) + 1\n    return grp, L\n\ndef err_rate(gt_s, s):\n    c_x = best_map(gt_s, s)\n    err_x = np.sum(gt_s[:] != c_x[:])\n    missrate = err_x.astype(float) / (gt_s.shape[0])\n    return missrate\n\n# ===========================================================================================\n# ====================================== Main Function ======================================\n# ===========================================================================================\nif __name__ == \"__main__\":\n    \n    if torch.cuda.is_available():   \n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    else: \n        device = torch.device('cpu')\n    from torchinfo import summary\n        \n#     class ConvAEIn(nn.Module):\n#         def __init__(self, params):\n#             super().__init__()\n#             kernelSize = params[\"kernelSize\"]\n#             numHidden = params[\"numHidden\"]\n\n#             self.batchSize = params[\"numSubj\"] * params[\"numPerSubj\"]\n\n#             self.padEncL1 = nn.ZeroPad2d((0, 2, 0, 2))\n#             self.encL1 = nn.Conv2d(1, numHidden[0], kernel_size=kernelSize[0], stride=2)\n\n#             self.padDecL1 = nn.ZeroPad2d((0, -1, 0, -1))\n#             self.decL1 = nn.ConvTranspose2d(numHidden[0], 1, kernel_size=kernelSize[0], stride=2)\n\n#         def forward(self, X):\n#             Z1 = F.relu(self.encL1(self.padEncL1(X)))\n\n#             output = F.relu(self.padDecL1(self.decL1(Z1)))\n#             return output\n# # =======================\n#     ae_in_params = {\"kernelSize\": [3],\n#         \"numHidden\":  [50],\n#         \"input_size\": [32, 32],\n#         \"numSubj\": 100,\n#         \"numPerSubj\": 72\n#         } # pre-trained model\n\n#     ae_in = ConvAEIn(params=ae_in_params)\n#     print(\"done!\")\n    \n    \n#     from torchinfo import summary\n#     summary(ae_in, input_size=(1, 32, 32), device=device,\n#             col_names=[\"input_size\",\"kernel_size\", \"output_size\", \"num_params\"], col_width=20,\n#             row_settings=[\"var_names\"],depth=5)\n    \n#######################################\n    print(\"Testing ConvAE...\")\n    \n    ae_params = {\"kernelSize\": [3],\n        \"numHidden\":  [50],\n        \"input_size\": [32, 32],\n        \"numSubj\": 8,\n        \"cte\": 1.0e-4,\n        \"rankE\": 10,\n        \"numPerSubj\": 8\n        } # pre-trained model\n    \n    class ConvAE(nn.Module):\n        def __init__(self, params):\n            super(ConvAE, self).__init__()\n            kernelSize = params[\"kernelSize\"]\n            numHidden = params[\"numHidden\"]\n            cte = params[\"cte\"]\n            numSubj = params[\"numSubj\"]\n            rankEs = params[\"rankE\"]\n\n            self.batchSize = numSubj * params[\"numPerSubj\"]\n\n            print(\"batchSize:\", self.batchSize)\n            self.padEncL1 = nn.ZeroPad2d((0, 2, 0, 2))\n            self.encL1 = nn.Conv2d(1, numHidden[0], kernel_size=kernelSize[0], stride=2)\n            self.resnet18 = ResNet18(in_channels=1)\n\n            cc = np.zeros((self.batchSize, rankEs))\n\n            self.C1 = nn.Parameter(Variable(torch.Tensor(cc), requires_grad=True))\n            print(\"C1Size:\", self.C1.shape)\n            self.padDecL1 = nn.ZeroPad2d((0, -1, 0, -1))\n            self.decL1 = nn.ConvTranspose2d(numHidden[0], 1, kernel_size=kernelSize[0], stride=2)\n\n        def forward(self, X):\n            Z1 = F.relu(self.resnet18(X))\n            print(\"Z1 shape:\", Z1.shape)\n            Y = (torch.matmul(self.C1, torch.transpose(self.C1, 0, 1))-torch.diag(torch.diag(torch.matmul(self.C1, torch.transpose(self.C1, 0, 1))))).mm(Z1.view(self.batchSize, -1))\n            Y = Y.view(Z1.size())\n\n            output = F.relu(self.padDecL1(self.decL1(Y)))\n            return Z1, Y, self.C1, output\n        \n    ae = ConvAE(params=ae_params)\n    dummy_input = torch.randn(64, 1, 32, 32)\n    out = ae(dummy_input)\n    print(\"out shape:\", out[3].shape)\n    \n    \n    summary(ae, input_size=(64,1, 32, 32), device=device,\n            col_names=[\"input_size\",\"kernel_size\", \"output_size\", \"num_params\"], col_width=20,\n            row_settings=[\"var_names\"],depth=5)\n    #########################\n    \n    # from torchvision import models\n    # print(\"testing Resnet...\")\n    # class ResNet18(nn.Module):\n    #     def __init__(self, in_channels=1):\n    #         super().__init__()\n    #         self.resnet = models.resnet18(weights=None)\n    #         self.resnet.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n    #         self.relu = nn.LeakyReLU()\n    #         # self.resnet.fc = nn.Linear(512, out_nodes)  # Flatten to 128 nodes\n    #         # Replace residual blocks in layers 2, 3, and 4 with identity blocks\n    #         self.resnet.layer2 = nn.Sequential(\n    #             nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n    #             nn.BatchNorm2d(64),\n    #             nn.LeakyReLU(),\n    #             nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n    #             nn.BatchNorm2d(64)\n    #         )\n    #         self.resnet.layer3 = nn.Sequential(\n    #             nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False),\n    #             nn.BatchNorm2d(128),\n    #             nn.LeakyReLU(),\n    #             nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False),\n    #             nn.BatchNorm2d(128)\n    #         )\n    #         self.resnet.layer4 = nn.Sequential(\n    #             nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False),\n    #             nn.BatchNorm2d(256),\n    #             nn.LeakyReLU(),\n    #             nn.Conv2d(256, 64, kernel_size=3, stride=1, padding=1, bias=False),\n    #             nn.BatchNorm2d(64))\n\n    #     def forward(self, x):\n    #         x = self.resnet.conv1(x)\n    #         x = self.resnet.bn1(x)\n    #         x = self.resnet.relu(x)\n    #         #x = self.resnet.maxpool(x)\n\n    #         x = self.resnet.layer1(x)\n    #         x = self.resnet.layer2(x)\n    #         x = self.resnet.layer3(x)\n    #         x = self.resnet.layer4(x)\n\n    #         return x\n    \n    \n    # resnet = ResNet18(in_channels=1)\n    # resnet.to(device=device)\n    # resnet_dummmy = torch.randn(1, 1, 128, 128).float().to(device)\n    # #resnet_dummmy.to(device)\n    # res_out = resnet(resnet_dummmy)\n    # print(\"res_out shape:\", res_out.shape)\n    \n    # import torch\n    # import torch.nn as nn\n    # import torchvision.models as models\n    # import torchinfo\n\n    # # Load the ResNet-18 model\n    # resnet18 = models.resnet18()\n\n    # # Create a random input tensor for summary\n    # dummy_input = torch.randn(1, 3, 224, 224)\n\n    # # Print the model summary using torchinfo\n    # summary = torchinfo.summary(resnet18, input_size=(1, 3, 224, 224),\n    #                                         col_names=[\"input_size\",\"kernel_size\", \"output_size\", \"num_params\"], col_width=20,\n    #          row_settings=[\"var_names\"],depth=5)\n    # print(summary)\n    \n    args = yaml.load(open(\"/kaggle/working/DLRSC/COIL100_config.yaml\", 'r'))\n    params = {}\n    params[\"numSubj\"] = 100\n    params[\"numPerSubj\"] = 72\n    params[\"lr\"] = args[\"training\"][\"lr\"]\n    params[\"T\"] = 1\n    params[\"numEpochs\"] = 10\n    params[\"lambda\"] = args[\"training\"][\"lambda\"]\n    params[\"gamma\"] = args[\"training\"][\"gamma\"]\n    params[\"cte\"] = args[\"training\"][\"cte\"]\n    params[\"seedFlag\"] = args[\"training\"][\"seedFlag\"]\n    params[\"seedValue\"] = args[\"training\"][\"seedValue\"]\n    params[\"post_proc\"] = args[\"training\"][\"post_proc\"]\n    params[\"dataPath\"] = \"/kaggle/working/DLRSC/Data/COIL100.mat\"\n    params[\"preTrainedModel\"] = \"/kaggle/working/DLRSC/PreTrained-COIL100.pt\"\n    params[\"kernelSize\"] = args[\"model\"][\"kernelSize\"]\n    params[\"numHidden\"] = args[\"model\"][\"numHidden\"]\n    params[\"input_size\"] = args[\"model\"][\"input_size\"]\n    params[\"rankE\"] = args[\"training\"][\"rankE\"] * params[\"numSubj\"]\n    params[\"indx\"] = 0\n    params[\"alpha\"] = 0.04\n    params[\"regparams\"] = 1.0\n    data = sio.loadmat(params[\"dataPath\"])\n\n    images = data['fea']\n    images = np.reshape(images, [images.shape[0], 1, params[\"input_size\"][0], params[\"input_size\"][1]])\n    params[\"label\"]  = data['gnd']\n\n\n    errorMean = subspaceClusteringMLRDSC(images, params)\n    print(\"====================================================\")\n    print('%d subjects:' % (params[\"numSubj\"]), \"Params: %d\" %(params[\"indx\"]))\n    print('Mean: %.4f%%' % (errorMean * 100))\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-08T18:45:18.162273Z","iopub.execute_input":"2023-07-08T18:45:18.162764Z","iopub.status.idle":"2023-07-08T19:20:37.983307Z","shell.execute_reply.started":"2023-07-08T18:45:18.162725Z","shell.execute_reply":"2023-07-08T19:20:37.982274Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"testing Resnet...\nTesting ConvAE...\nbatchSize: 64\nC1Size: torch.Size([64, 10])\nZ1 shape: torch.Size([64, 50, 16, 16])\nout shape: torch.Size([64, 1, 32, 32])\nZ1 shape: torch.Size([64, 50, 16, 16])\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_28/1888261825.py:429: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n  args = yaml.load(open(\"/kaggle/working/DLRSC/COIL100_config.yaml\", 'r'))\n/opt/conda/lib/python3.10/site-packages/torch/serialization.py:854: UserWarning: Couldn't retrieve source code for container of type ConvAEIn. It won't be checked for correctness upon loading.\n  warnings.warn(\"Couldn't retrieve source code for container of \"\n/opt/conda/lib/python3.10/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.padding.ZeroPad2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n  warnings.warn(msg, SourceChangeWarning)\n/opt/conda/lib/python3.10/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n  warnings.warn(msg, SourceChangeWarning)\n/opt/conda/lib/python3.10/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.conv.ConvTranspose2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n  warnings.warn(msg, SourceChangeWarning)\n","output_type":"stream"},{"name":"stdout","text":"batchSize: 7200\nC1Size: torch.Size([7200, 1000])\nZ1 shape: torch.Size([7200, 50, 16, 16])\nZ1 shape: torch.Size([7200, 50, 16, 16])\nZ1 shape: torch.Size([7200, 50, 16, 16])\nZ1 shape: torch.Size([7200, 50, 16, 16])\nZ1 shape: torch.Size([7200, 50, 16, 16])\nZ1 shape: torch.Size([7200, 50, 16, 16])\nLosses  Reconstruction: 1401.96850586     Expression: 435312096.00000000     Regularization: 12.21479225\nAccuracy after 5 Iterations: 0.3710\nZ1 shape: torch.Size([7200, 50, 16, 16])\nZ1 shape: torch.Size([7200, 50, 16, 16])\nZ1 shape: torch.Size([7200, 50, 16, 16])\nZ1 shape: torch.Size([7200, 50, 16, 16])\nZ1 shape: torch.Size([7200, 50, 16, 16])\nLosses  Reconstruction: 204.57675171     Expression: 106712352.00000000     Regularization: 9.08557415\nAccuracy after 10 Iterations: 0.3378\n====================================================\n100 subjects: Params: 0\nMean: 66.2222%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}